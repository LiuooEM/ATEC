{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T07:41:18.563706Z",
     "start_time": "2021-05-27T07:41:16.301029Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from subprocess import check_output\n",
    "\n",
    "from utils_test import save_data, predict_boundary_test, predict_number_test, label_res14_xml, label_res15_xml, label_res16_xml, label_lap_xml\n",
    "from utils_train import generate_idx_word\n",
    "from generate_boundary_pred_label import return_predicted_boundary_test_label, generate_boundary_test_data, load_data_test, squad_test_data, save_test\n",
    "from generate_number_pred_label import generate_number_test_data, json_to_csv, return_predicted_number_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T07:41:18.567203Z",
     "start_time": "2021-05-27T07:41:18.564679Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T07:41:18.576305Z",
     "start_time": "2021-05-27T07:41:18.568291Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, gen_emb, domain_emb, num_classes=3, dropout=0.5, crf=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
    "        self.gen_embedding.weight=torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
    "        self.domain_embedding = torch.nn.Embedding(domain_emb.shape[0], domain_emb.shape[1])\n",
    "        self.domain_embedding.weight=torch.nn.Parameter(torch.from_numpy(domain_emb), requires_grad=False)\n",
    "        \n",
    "        self.conv1=torch.nn.Conv1d(gen_emb.shape[1], 128, 5, padding=2)\n",
    "        self.conv2=torch.nn.Conv1d(gen_emb.shape[1], 128, 3, padding=1)\n",
    "        self.dropout=torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv3=torch.nn.Conv1d(256, 256, 5, padding=2)\n",
    "        self.conv4=torch.nn.Conv1d(256, 256, 5, padding=2)\n",
    "        self.conv5=torch.nn.Conv1d(256, 256, 5, padding=2)\n",
    "        self.linear_ae=torch.nn.Linear(256, num_classes)\n",
    "        self.crf_flag=crf\n",
    "        if self.crf_flag:\n",
    "            from allennlp.modules import ConditionalRandomField\n",
    "            self.crf=ConditionalRandomField(num_classes)\n",
    "          \n",
    "    def forward(self, x, x_len, x_mask, x_tag=None, testing=True):\n",
    "        x_emb=torch.cat((self.gen_embedding(x), self.domain_embedding(x)), dim=2)\n",
    "        x_emb=self.dropout(x_emb).transpose(1, 2)\n",
    "        x_conv=torch.nn.functional.relu(torch.cat((self.conv1(x_emb), self.conv2(x_emb)), dim=1))\n",
    "        \n",
    "        x_conv=self.dropout(x_conv)\n",
    "        x_conv=torch.nn.functional.relu(self.conv3(x_conv))\n",
    "        x_conv=self.dropout(x_conv)\n",
    "        x_conv=torch.nn.functional.relu(self.conv4(x_conv))\n",
    "        x_conv=self.dropout(x_conv)\n",
    "        x_conv=torch.nn.functional.relu(self.conv5(x_conv))\n",
    "        x_conv=x_conv.transpose(1, 2)\n",
    "        x_logit=self.linear_ae(x_conv)\n",
    "        if testing:\n",
    "            if self.crf_flag:\n",
    "                score=self.crf.viterbi_tags(x_logit, x_mask)\n",
    "            else:\n",
    "                x_logit=x_logit.transpose(2, 0)\n",
    "                score=torch.nn.functional.log_softmax(x_logit).transpose(2, 0)\n",
    "        else:\n",
    "            if self.crf_flag:\n",
    "                score=-self.crf(x_logit, x_tag, x_mask)\n",
    "            else:\n",
    "                x_logit=torch.nn.utils.rnn.pack_padded_sequence(x_logit, x_len, batch_first=True)\n",
    "                score=torch.nn.functional.nll_loss(torch.nn.functional.log_softmax(x_logit.data), x_tag.data)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T07:41:18.588701Z",
     "start_time": "2021-05-27T07:41:18.577283Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, test_X, test_y, raw_X, domain, command, template, run_epoch, boundary_process, crf, generate_data, batch_size, num_process):\n",
    "    pred_y = np.zeros((test_X.shape[0], test_X.shape[1]), np.int16)\n",
    "    idx_word = generate_idx_word(domain)\n",
    "    model.eval()\n",
    "\n",
    "    for offset in range(0, test_X.shape[0], batch_size):\n",
    "        batch_test_X_len = np.sum(test_X[offset:offset+  batch_size] != 0, axis = 1)\n",
    "        batch_idx = batch_test_X_len.argsort()[::-1]\n",
    "        batch_test_X_len = batch_test_X_len[batch_idx]\n",
    "        batch_test_X_mask = (test_X[offset:offset + batch_size] != 0)[batch_idx].astype(np.uint8)\n",
    "        batch_test_X = test_X[offset:offset + batch_size][batch_idx]\n",
    "        batch_test_X_mask = torch.autograd.Variable(torch.from_numpy(batch_test_X_mask).long().cuda())\n",
    "        batch_test_X = torch.autograd.Variable(torch.from_numpy(batch_test_X).long().cuda())\n",
    "        batch_pred_y = model(batch_test_X, batch_test_X_len, batch_test_X_mask, testing = True)\n",
    "        r_idx = batch_idx.argsort()\n",
    "        if crf:\n",
    "            batch_pred_y = [batch_pred_y[idx] for idx in r_idx]\n",
    "            for ix in range(len(batch_pred_y)):\n",
    "                for jx in range(len(batch_pred_y[ix][0])):\n",
    "                    pred_y[offset + ix, jx] = batch_pred_y[ix][0][jx]\n",
    "        else:\n",
    "            batch_pred_y = batch_pred_y.data.cpu().numpy().argmax(axis = 2)[r_idx]\n",
    "            pred_y[offset:offset + batch_size, :batch_pred_y.shape[1]] = batch_pred_y\n",
    "    assert len(pred_y) == len(test_X)\n",
    "    \n",
    "    if generate_data:\n",
    "        results = []\n",
    "        for j_th in range(len(test_X)):\n",
    "            result = []\n",
    "            words_num = test_X[j_th]\n",
    "            words_str = []\n",
    "            test_y_part = test_y[j_th]\n",
    "            for w in words_num:\n",
    "                if(w != 0):\n",
    "                    words_str.append(idx_word[w])\n",
    "            pred = pred_y[j_th]\n",
    "            for words_str, test_y_part, pred in zip(words_str, test_y_part, pred):\n",
    "                result.append(\" \".join([words_str, str(test_y_part), str(pred)]))\n",
    "            results.append(result)\n",
    "        save_data(domain, results, run_epoch)\n",
    "\n",
    "    if boundary_process:\n",
    "        generate_boundary_test_data(domain, run_epoch)\n",
    "        predict_boundary_test(domain, run_epoch)\n",
    "        pred_y = return_predicted_boundary_test_label(domain, run_epoch)\n",
    "        \n",
    "    if num_process:\n",
    "        if boundary_process:\n",
    "            results = []\n",
    "            for j_th in range(len(test_X)):\n",
    "                result = []\n",
    "                words_num = test_X[j_th]\n",
    "                words_str = []\n",
    "                test_y_part = test_y[j_th]\n",
    "                for w in words_num:\n",
    "                    if(w != 0):\n",
    "                        words_str.append(idx_word[w])\n",
    "                pred = pred_y[j_th]\n",
    "                for words_str, test_y_part, pred in zip(words_str, test_y_part, pred):\n",
    "                    result.append(\" \".join([words_str, str(test_y_part), str(pred)]))\n",
    "                results.append(result)\n",
    "            save_data(domain, results, run_epoch)\n",
    "            generate_number_test_data(domain, run_epoch)\n",
    "            json_to_csv(domain, run_epoch)\n",
    "            predict_number_test(domain, run_epoch)\n",
    "            pred_y = return_predicted_number_test_label(domain, run_epoch, pred_y)\n",
    "        else:\n",
    "            generate_number_test_data(domain, run_epoch)\n",
    "            json_to_csv(domain, run_epoch)\n",
    "            predict_number_test(domain, run_epoch)\n",
    "            pred_y = return_predicted_number_test_label(domain, run_epoch, pred_y)\n",
    "            \n",
    "    command = command.split()\n",
    "    if domain == 'restaurant':\n",
    "        label_res16_xml(template, command[6], raw_X, pred_y)\n",
    "        acc = check_output(command).split()\n",
    "        print(acc)\n",
    "        return float(acc[7][4:]), float(acc[8][4:]), float(acc[9][10:])\n",
    "    elif domain == 'laptop':\n",
    "        label_lap_xml(template, command[4], raw_X, pred_y)\n",
    "        acc = check_output(command).split()\n",
    "        print(acc)\n",
    "        return float(acc[9]), float(acc[12]), float(acc[15])\n",
    "    elif domain == 'restaurant14':\n",
    "        label_res14_xml(template, command[4], raw_X, pred_y)\n",
    "        acc = check_output(command).split()\n",
    "        print(acc)\n",
    "        return float(acc[9]), float(acc[12]), float(acc[15])\n",
    "    elif domain == 'restaurant15':\n",
    "        label_res15_xml(template, command[5], raw_X, pred_y)\n",
    "        acc = check_output(command).split()\n",
    "        print(acc)\n",
    "        return float(acc[7][4:]), float(acc[8][4:]), float(acc[9][10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T07:41:18.593877Z",
     "start_time": "2021-05-27T07:41:18.589509Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(runs, data_dir, model_dir, domain, boundary_process, crf, generate_data, batch_size, num_process, command, template):\n",
    "    ae_data=np.load(data_dir+domain+\".npz\")\n",
    "    with open(data_dir+domain+\"_raw_test.json\") as f:\n",
    "        raw_X=json.load(f)\n",
    "    results=[]\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for r in range(runs):\n",
    "        model=torch.load(model_dir+domain+str(r))\n",
    "        precision, recall, result = test(model, ae_data['test_X'], ae_data['test_y'], raw_X, domain, command, template, r, boundary_process, crf, generate_data, batch_size, num_process)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        results.append(result)\n",
    "    with open('evaluate_log/DECNN/evaluate.txt', 'a') as log:\n",
    "        log.write(str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())) + '\\n')\n",
    "        log.write('num_process: ' + str(num_process) + '\\n')\n",
    "        log.write('boundary_process: ' + str(boundary_process) + '\\n')\n",
    "        log.write('seed is: ' + str(seed) + '\\n')\n",
    "        log.write('batch_size is: ' + str(batch_size) + '\\n')\n",
    "        log.write('domain is: ' + domain + '\\n')\n",
    "        log.write('result is:' + str(sum(results)/len(results)) + '\\n' + '\\n')\n",
    "    print('P:', sum(precisions)/len(precisions))\n",
    "    print('R:', sum(recalls)/len(recalls))\n",
    "    print('F1:', sum(results)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T07:42:38.588761Z",
     "start_time": "2021-05-27T07:41:18.594621Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_dir', type=str, default=\"model/DECNN/\")\n",
    "    parser.add_argument('--batch_size', type=int, default=64)\n",
    "    parser.add_argument('--runs', type=int, default=5)\n",
    "    #you can set this parameter to [laptop], [reataurant], [reataurant14], [reataurant15]\n",
    "    parser.add_argument('--domain', type=str, default=\"laptop\")\n",
    "    #if you set the above parameter--domian to [laptop] or [restaurant], you need to set this parameter to [data/prep_data/]\n",
    "    #else you need to set this parameter to [data/prep_data_15/]\n",
    "    parser.add_argument('--data_dir', type=str, default=\"data/prep_data/\")\n",
    "    #you can replace the softmax layer with CRF layer\n",
    "    parser.add_argument('--crf', type=bool, default=False)\n",
    "    parser.add_argument('--generate_data', type=bool, default=True)\n",
    "    #Aspect Number Determining module\n",
    "    parser.add_argument('--num_process', type=bool, default=True)\n",
    "    #Aspect Boundary MOdifying module\n",
    "    parser.add_argument('--boundary_process', type=bool, default=True)\n",
    "    args = parser.parse_known_args()[0]\n",
    "\n",
    "    if args.domain=='restaurant':\n",
    "        command=\"java -cp script/A.jar absa16.Do Eval -prd data/official_data/pred.xml -gld data/official_data/EN_REST_SB1_TEST.xml.gold -evs 2 -phs A -sbt SB1\"\n",
    "        template=\"data/official_data/EN_REST_SB1_TEST.xml.A\"\n",
    "    elif args.domain=='laptop':\n",
    "        command=\"java -cp script/eval.jar Main.Aspects data/official_data/pred.xml data/official_data/Laptops_Test_Gold.xml\"\n",
    "        template=\"data/official_data/Laptops_Test_Data_PhaseA.xml\"\n",
    "    elif args.domain=='restaurant14':\n",
    "        command=\"java -cp script/eval.jar Main.Aspects data/official_data/pred.xml data/official_data/Restaurants_Test_Gold.xml\"\n",
    "        template=\"data/official_data/Restaurants_Test_Data_PhaseA.xml\"\n",
    "    elif args.domain=='restaurant15':\n",
    "        command=\"java -cp script/A.jar absa15.Do Eval data/official_data/pred.xml data/official_data/ABSA15_Restaurants_Test.xml 2 0\"\n",
    "        template=\"data/official_data/ABSA15_Restaurants_Test_template.xml\"\n",
    "    evaluate(args.runs, args.data_dir, args.model_dir, args.domain, args.boundary_process, args.crf, args.generate_data, args.batch_size, args.num_process, command, template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensource",
   "language": "python",
   "name": "opensource"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
